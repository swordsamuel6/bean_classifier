{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder, MinMaxScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "import keras_tuner as kt\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing the data, preprocessing it, and splitting into train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "bean_data = pd.read_csv('Dry_Bean_Dataset.csv')\n",
    "\n",
    "X=bean_data.drop(columns=['Class'])\n",
    "\n",
    "min_max = MinMaxScaler(feature_range=(-1, 1))\n",
    "X_scaled = min_max.fit_transform(X)\n",
    "X_scaled = pd.DataFrame(X_scaled)\n",
    "X_scaled\n",
    "\n",
    "y = bean_data.Class\n",
    "# Encode labels if they are categorical\n",
    "label_encoder = LabelEncoder()\n",
    "y = label_encoder.fit_transform(y)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0\n",
       "3    0.260562\n",
       "6    0.193699\n",
       "5    0.148880\n",
       "4    0.141624\n",
       "2    0.119765\n",
       "0    0.097079\n",
       "1    0.038391\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(y_train).value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0\n",
       "3    0.260375\n",
       "6    0.193537\n",
       "5    0.149100\n",
       "4    0.141755\n",
       "2    0.119721\n",
       "0    0.097319\n",
       "1    0.038193\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(y_test).value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Forming the model and making predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model\n",
    "model = Sequential([\n",
    "    Dense(64, activation='relu', input_shape=(16,)),  # Input layer with 16 features\n",
    "    Dropout(0.5),\n",
    "    Dense(32, activation='relu'),  # Hidden layer\n",
    "    Dropout(0.5),\n",
    "    Dense(len(np.unique(y)), activation='softmax')  # Output layer for multi-class classification\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',  # Use sparse if labels are integers\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(X_train, y_train, \n",
    "                    validation_split=0.2, \n",
    "                    epochs=50, \n",
    "                    batch_size=32, \n",
    "                    verbose=1)\n",
    "\n",
    "# Evaluate on the test set\n",
    "test_loss, test_accuracy = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(f\"Test Accuracy: {test_accuracy * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reloading Tuner from my_dir\\tune_tabular_model\\tuner0.json\n",
      "Best Hyperparameters: {'units_layer1': 192, 'dropout_layer1': 0.30000000000000004, 'units_layer2': 64, 'dropout_layer2': 0.30000000000000004, 'learning_rate': 0.001}\n",
      "Epoch 1/50\n",
      "273/273 [==============================] - 3s 4ms/step - loss: 0.7560 - accuracy: 0.7254 - val_loss: 0.3134 - val_accuracy: 0.8972\n",
      "Epoch 2/50\n",
      "273/273 [==============================] - 1s 3ms/step - loss: 0.3529 - accuracy: 0.8765 - val_loss: 0.2734 - val_accuracy: 0.9091\n",
      "Epoch 3/50\n",
      "273/273 [==============================] - 1s 3ms/step - loss: 0.3071 - accuracy: 0.8931 - val_loss: 0.2390 - val_accuracy: 0.9105\n",
      "Epoch 4/50\n",
      "273/273 [==============================] - 1s 3ms/step - loss: 0.2855 - accuracy: 0.9010 - val_loss: 0.2258 - val_accuracy: 0.9151\n",
      "Epoch 5/50\n",
      "273/273 [==============================] - 1s 3ms/step - loss: 0.2737 - accuracy: 0.9013 - val_loss: 0.2215 - val_accuracy: 0.9201\n",
      "Epoch 6/50\n",
      "273/273 [==============================] - 1s 3ms/step - loss: 0.2704 - accuracy: 0.9068 - val_loss: 0.2205 - val_accuracy: 0.9215\n",
      "Epoch 7/50\n",
      "273/273 [==============================] - 1s 3ms/step - loss: 0.2583 - accuracy: 0.9119 - val_loss: 0.2212 - val_accuracy: 0.9233\n",
      "Epoch 8/50\n",
      "273/273 [==============================] - 1s 3ms/step - loss: 0.2581 - accuracy: 0.9107 - val_loss: 0.2244 - val_accuracy: 0.9256\n",
      "Epoch 9/50\n",
      "273/273 [==============================] - 1s 3ms/step - loss: 0.2517 - accuracy: 0.9098 - val_loss: 0.2146 - val_accuracy: 0.9206\n",
      "Epoch 10/50\n",
      "273/273 [==============================] - 1s 3ms/step - loss: 0.2514 - accuracy: 0.9124 - val_loss: 0.2266 - val_accuracy: 0.9252\n",
      "Epoch 11/50\n",
      "273/273 [==============================] - 1s 3ms/step - loss: 0.2449 - accuracy: 0.9145 - val_loss: 0.2096 - val_accuracy: 0.9238\n",
      "Epoch 12/50\n",
      "273/273 [==============================] - 1s 3ms/step - loss: 0.2433 - accuracy: 0.9127 - val_loss: 0.2041 - val_accuracy: 0.9284\n",
      "Epoch 13/50\n",
      "273/273 [==============================] - 1s 3ms/step - loss: 0.2404 - accuracy: 0.9145 - val_loss: 0.2056 - val_accuracy: 0.9279\n",
      "Epoch 14/50\n",
      "273/273 [==============================] - 1s 3ms/step - loss: 0.2339 - accuracy: 0.9160 - val_loss: 0.2124 - val_accuracy: 0.9284\n",
      "Epoch 15/50\n",
      "273/273 [==============================] - 1s 3ms/step - loss: 0.2349 - accuracy: 0.9155 - val_loss: 0.2091 - val_accuracy: 0.9284\n",
      "Epoch 16/50\n",
      "273/273 [==============================] - 1s 3ms/step - loss: 0.2299 - accuracy: 0.9176 - val_loss: 0.2016 - val_accuracy: 0.9298\n",
      "Epoch 17/50\n",
      "273/273 [==============================] - 1s 3ms/step - loss: 0.2297 - accuracy: 0.9176 - val_loss: 0.2137 - val_accuracy: 0.9187\n",
      "Epoch 18/50\n",
      "273/273 [==============================] - 1s 3ms/step - loss: 0.2320 - accuracy: 0.9155 - val_loss: 0.2090 - val_accuracy: 0.9201\n",
      "Epoch 19/50\n",
      "273/273 [==============================] - 1s 3ms/step - loss: 0.2332 - accuracy: 0.9165 - val_loss: 0.2010 - val_accuracy: 0.9238\n",
      "Epoch 20/50\n",
      "273/273 [==============================] - 1s 3ms/step - loss: 0.2290 - accuracy: 0.9197 - val_loss: 0.2060 - val_accuracy: 0.9229\n",
      "Epoch 21/50\n",
      "273/273 [==============================] - 1s 3ms/step - loss: 0.2263 - accuracy: 0.9163 - val_loss: 0.2113 - val_accuracy: 0.9256\n",
      "Epoch 22/50\n",
      "273/273 [==============================] - 1s 3ms/step - loss: 0.2297 - accuracy: 0.9196 - val_loss: 0.2060 - val_accuracy: 0.9320\n",
      "Epoch 23/50\n",
      "273/273 [==============================] - 1s 3ms/step - loss: 0.2284 - accuracy: 0.9217 - val_loss: 0.1940 - val_accuracy: 0.9343\n",
      "Epoch 24/50\n",
      "273/273 [==============================] - 1s 3ms/step - loss: 0.2221 - accuracy: 0.9214 - val_loss: 0.1934 - val_accuracy: 0.9339\n",
      "Epoch 25/50\n",
      "273/273 [==============================] - 1s 3ms/step - loss: 0.2212 - accuracy: 0.9214 - val_loss: 0.1947 - val_accuracy: 0.9307\n",
      "Epoch 26/50\n",
      "273/273 [==============================] - 1s 3ms/step - loss: 0.2220 - accuracy: 0.9207 - val_loss: 0.2072 - val_accuracy: 0.9311\n",
      "Epoch 27/50\n",
      "273/273 [==============================] - 1s 3ms/step - loss: 0.2201 - accuracy: 0.9202 - val_loss: 0.2124 - val_accuracy: 0.9169\n",
      "Epoch 28/50\n",
      "273/273 [==============================] - 1s 3ms/step - loss: 0.2211 - accuracy: 0.9187 - val_loss: 0.1979 - val_accuracy: 0.9252\n",
      "Epoch 29/50\n",
      "273/273 [==============================] - 1s 3ms/step - loss: 0.2180 - accuracy: 0.9216 - val_loss: 0.1968 - val_accuracy: 0.9325\n",
      "Epoch 30/50\n",
      "273/273 [==============================] - 1s 3ms/step - loss: 0.2141 - accuracy: 0.9243 - val_loss: 0.2002 - val_accuracy: 0.9330\n",
      "Epoch 31/50\n",
      "273/273 [==============================] - 1s 3ms/step - loss: 0.2122 - accuracy: 0.9249 - val_loss: 0.1922 - val_accuracy: 0.9284\n",
      "Epoch 32/50\n",
      "273/273 [==============================] - 1s 3ms/step - loss: 0.2169 - accuracy: 0.9222 - val_loss: 0.1895 - val_accuracy: 0.9348\n",
      "Epoch 33/50\n",
      "273/273 [==============================] - 1s 3ms/step - loss: 0.2130 - accuracy: 0.9237 - val_loss: 0.1989 - val_accuracy: 0.9311\n",
      "Epoch 34/50\n",
      "273/273 [==============================] - 1s 3ms/step - loss: 0.2156 - accuracy: 0.9232 - val_loss: 0.2010 - val_accuracy: 0.9325\n",
      "Epoch 35/50\n",
      "273/273 [==============================] - 1s 3ms/step - loss: 0.2148 - accuracy: 0.9206 - val_loss: 0.2031 - val_accuracy: 0.9320\n",
      "Epoch 36/50\n",
      "273/273 [==============================] - 1s 3ms/step - loss: 0.2141 - accuracy: 0.9238 - val_loss: 0.2015 - val_accuracy: 0.9238\n",
      "Epoch 37/50\n",
      "273/273 [==============================] - 1s 3ms/step - loss: 0.2155 - accuracy: 0.9218 - val_loss: 0.1960 - val_accuracy: 0.9279\n",
      "Epoch 38/50\n",
      "273/273 [==============================] - 1s 3ms/step - loss: 0.2157 - accuracy: 0.9214 - val_loss: 0.1932 - val_accuracy: 0.9311\n",
      "Epoch 39/50\n",
      "273/273 [==============================] - 1s 3ms/step - loss: 0.2114 - accuracy: 0.9263 - val_loss: 0.2051 - val_accuracy: 0.9178\n",
      "Epoch 40/50\n",
      "273/273 [==============================] - 1s 3ms/step - loss: 0.2116 - accuracy: 0.9233 - val_loss: 0.2015 - val_accuracy: 0.9275\n",
      "Epoch 41/50\n",
      "273/273 [==============================] - 1s 3ms/step - loss: 0.2107 - accuracy: 0.9218 - val_loss: 0.1959 - val_accuracy: 0.9343\n",
      "Epoch 42/50\n",
      "273/273 [==============================] - 1s 3ms/step - loss: 0.2120 - accuracy: 0.9223 - val_loss: 0.1912 - val_accuracy: 0.9316\n",
      "Epoch 43/50\n",
      "273/273 [==============================] - 1s 3ms/step - loss: 0.2095 - accuracy: 0.9239 - val_loss: 0.1965 - val_accuracy: 0.9252\n",
      "Epoch 44/50\n",
      "273/273 [==============================] - 1s 3ms/step - loss: 0.2094 - accuracy: 0.9253 - val_loss: 0.1944 - val_accuracy: 0.9339\n",
      "Epoch 45/50\n",
      "273/273 [==============================] - 1s 3ms/step - loss: 0.2104 - accuracy: 0.9218 - val_loss: 0.1895 - val_accuracy: 0.9343\n",
      "Epoch 46/50\n",
      "273/273 [==============================] - 1s 3ms/step - loss: 0.2082 - accuracy: 0.9257 - val_loss: 0.1910 - val_accuracy: 0.9325\n",
      "Epoch 47/50\n",
      "273/273 [==============================] - 1s 3ms/step - loss: 0.2092 - accuracy: 0.9240 - val_loss: 0.1956 - val_accuracy: 0.9247\n",
      "Epoch 48/50\n",
      "273/273 [==============================] - 1s 3ms/step - loss: 0.2098 - accuracy: 0.9256 - val_loss: 0.1892 - val_accuracy: 0.9380\n",
      "Epoch 49/50\n",
      "273/273 [==============================] - 1s 3ms/step - loss: 0.2021 - accuracy: 0.9241 - val_loss: 0.1991 - val_accuracy: 0.9362\n",
      "Epoch 50/50\n",
      "273/273 [==============================] - 1s 3ms/step - loss: 0.2067 - accuracy: 0.9261 - val_loss: 0.1956 - val_accuracy: 0.9238\n"
     ]
    }
   ],
   "source": [
    "# Define the model-building function\n",
    "def build_model(hp):\n",
    "    model = Sequential()\n",
    "    # Input layer and first hidden layer\n",
    "    model.add(Dense(\n",
    "        units=hp.Int('units_layer1', min_value=32, max_value=256, step=32),\n",
    "        activation='relu',\n",
    "        input_shape=(16,)\n",
    "    ))\n",
    "    model.add(Dropout(hp.Float('dropout_layer1', min_value=0.2, max_value=0.5, step=0.1)))\n",
    "\n",
    "    # Second hidden layer\n",
    "    model.add(Dense(\n",
    "        units=hp.Int('units_layer2', min_value=32, max_value=128, step=32),\n",
    "        activation='relu'\n",
    "    ))\n",
    "    model.add(Dropout(hp.Float('dropout_layer2', min_value=0.2, max_value=0.5, step=0.1)))\n",
    "\n",
    "    # Output layer\n",
    "    model.add(Dense(len(np.unique(y)), activation='softmax'))\n",
    "\n",
    "    # Compile the model\n",
    "    model.compile(\n",
    "        optimizer=Adam(learning_rate=hp.Choice('learning_rate', [1e-2, 1e-3, 1e-4])),\n",
    "        loss='sparse_categorical_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    return model\n",
    "\n",
    "# Define the tuner\n",
    "tuner = kt.RandomSearch(\n",
    "    build_model,\n",
    "    objective='val_accuracy',\n",
    "    max_trials=10,  # Number of models to try\n",
    "    directory='my_dir',\n",
    "    project_name='tune_tabular_model'\n",
    ")\n",
    "\n",
    "# Run the tuner\n",
    "tuner.search(X_train, y_train, validation_split=0.2, epochs=50, batch_size=32)\n",
    "\n",
    "# Get the best hyperparameters\n",
    "best_hps = tuner.get_best_hyperparameters(num_trials=1)[0]\n",
    "print(f\"Best Hyperparameters: {best_hps.values}\")\n",
    "\n",
    "# Train the best model\n",
    "best_model = tuner.hypermodel.build(best_hps)\n",
    "history = best_model.fit(X_train, y_train, validation_split=0.2, epochs=50, batch_size=32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "86/86 [==============================] - 1s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "# predictions\n",
    "predictions = best_model.predict(X_test)\n",
    "predicted_classes = np.argmax(predictions, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Add these above later\n",
    "# Libraries for metrics and evaluation\n",
    "import numpy as np\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, classification_report, confusion_matrix,\n",
    "    log_loss, roc_auc_score, roc_curve, precision_recall_curve,\n",
    "    cohen_kappa_score\n",
    ")\n",
    "from sklearn.preprocessing import label_binarize\n",
    "\n",
    "# Libraries for visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "\n",
    "# TensorFlow/Keras for top-k accuracy (if needed)\n",
    "from tensorflow.keras.metrics import top_k_categorical_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 92.07%\n"
     ]
    }
   ],
   "source": [
    "# Evaluate on the test set\n",
    "test_loss, test_accuracy = best_model.evaluate(X_test, y_test, verbose=0)\n",
    "print(f\"Test Accuracy: {test_accuracy * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    BARBUNYA       0.94      0.89      0.92       265\n",
      "      BOMBAY       1.00      1.00      1.00       104\n",
      "        CALI       0.91      0.95      0.93       326\n",
      "    DERMASON       0.94      0.88      0.91       709\n",
      "       HOROZ       0.97      0.95      0.96       386\n",
      "       SEKER       0.96      0.95      0.95       406\n",
      "        SIRA       0.83      0.91      0.87       527\n",
      "\n",
      "    accuracy                           0.92      2723\n",
      "   macro avg       0.93      0.93      0.93      2723\n",
      "weighted avg       0.92      0.92      0.92      2723\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, predicted_classes, target_names=label_encoder.classes_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
